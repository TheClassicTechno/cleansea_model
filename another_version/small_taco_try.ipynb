{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small taco try",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "authorship_tag": "ABX9TyONUXkQDqVrnHA2JsISIxUC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheClassicTechno/cleansea_model/blob/main/another_version/small_taco_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6i0R_D6Gk89",
        "outputId": "4bdaf430-0d21-4fc4-8b3e-7643f4e7a72b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmfB3Q5xGXAy",
        "outputId": "3f9ad772-9811-448c-e564-915e428bbf11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 172 files belonging to 5 classes.\n",
            "Using 138 files for training.\n",
            "Found 172 files belonging to 5 classes.\n",
            "Using 34 files for validation.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 227, 227, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 227, 227, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 113, 113, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 113, 113, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               6422656   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,446,885\n",
            "Trainable params: 6,446,885\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "#processing images\n",
        "bottles1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/bottles'\n",
        "cans1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/cans'\n",
        "containers1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/containers'\n",
        "paper1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/paper'\n",
        "plastic1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/plastic'\n",
        "\n",
        "#all images are 227x227 in RGB so 227, 227, 3\n",
        "bottles = [cv2.imread(image) for image in glob.glob(bottles1)]\n",
        "cans = [cv2.imread(image) for image in glob.glob(cans1)]\n",
        "containers = [cv2.imread(image) for image in glob.glob(containers1)]\n",
        "paper = [cv2.imread(image) for image in glob.glob(paper1)]\n",
        "plastic = [cv2.imread(image) for image in glob.glob(plastic1)]\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/TEAM9SURESTART/taco',\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    seed = 24,  \n",
        "    image_size = (227, 227),\n",
        "    batch_size = 8\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/TEAM9SURESTART/taco',\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = 24,  \n",
        "    image_size = (227, 227),\n",
        "    batch_size = 8\n",
        ")\n",
        "\n",
        "\n",
        "from scipy.stats import zscore\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample df\n",
        "\n",
        "# Calculate the zscores and drop zscores into new column\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n",
        "model = Sequential ([\n",
        "    layers.Rescaling(1./255, input_shape = (227, 227, 3)),\n",
        "    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.Dense(5, activation = 'softmax')\n",
        "])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5roqeB1xUkB3",
        "outputId": "6e586aa4-46d2-45f6-873e-f94f9c19c4fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rT16MKUCHn8M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=['accuracy'],  run_eagerly=True\n",
        ")\n",
        "model.fit (\n",
        "    train_dataset, \n",
        "    validation_data = val_dataset,\n",
        "    epochs = 120\n",
        ")\n",
        "#model.save('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CaGQFS2Hlk6",
        "outputId": "75ad46a4-a57b-4e0a-bbb2-043631a933d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "18/18 [==============================] - 26s 196ms/step - loss: 2.1523 - accuracy: 0.2971 - val_loss: 1.5028 - val_accuracy: 0.2353\n",
            "Epoch 2/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.5023 - accuracy: 0.3623 - val_loss: 1.4031 - val_accuracy: 0.4118\n",
            "Epoch 3/120\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 1.2977 - accuracy: 0.4783 - val_loss: 1.3005 - val_accuracy: 0.5000\n",
            "Epoch 4/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.1049 - accuracy: 0.6087 - val_loss: 1.4223 - val_accuracy: 0.5294\n",
            "Epoch 5/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.8286 - accuracy: 0.7174 - val_loss: 1.2664 - val_accuracy: 0.5000\n",
            "Epoch 6/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.5080 - accuracy: 0.8478 - val_loss: 1.5908 - val_accuracy: 0.4412\n",
            "Epoch 7/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.4042 - accuracy: 0.8551 - val_loss: 1.5967 - val_accuracy: 0.5000\n",
            "Epoch 8/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.2721 - accuracy: 0.9348 - val_loss: 1.7869 - val_accuracy: 0.5000\n",
            "Epoch 9/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1466 - accuracy: 0.9493 - val_loss: 1.7900 - val_accuracy: 0.5000\n",
            "Epoch 10/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0788 - accuracy: 0.9783 - val_loss: 1.8276 - val_accuracy: 0.4706\n",
            "Epoch 11/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1242 - accuracy: 0.9710 - val_loss: 2.0519 - val_accuracy: 0.5588\n",
            "Epoch 12/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0828 - accuracy: 0.9638 - val_loss: 1.7896 - val_accuracy: 0.5588\n",
            "Epoch 13/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0609 - accuracy: 0.9928 - val_loss: 2.1122 - val_accuracy: 0.5588\n",
            "Epoch 14/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 2.6369 - val_accuracy: 0.5000\n",
            "Epoch 15/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0867 - accuracy: 0.9783 - val_loss: 2.1633 - val_accuracy: 0.5588\n",
            "Epoch 16/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.4548 - accuracy: 0.8478 - val_loss: 1.6586 - val_accuracy: 0.4412\n",
            "Epoch 17/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1476 - accuracy: 0.9420 - val_loss: 1.6751 - val_accuracy: 0.4706\n",
            "Epoch 18/120\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0462 - accuracy: 0.9928 - val_loss: 2.5526 - val_accuracy: 0.5294\n",
            "Epoch 19/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.6697 - val_accuracy: 0.5294\n",
            "Epoch 20/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8796 - val_accuracy: 0.5000\n",
            "Epoch 21/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9604 - val_accuracy: 0.5000\n",
            "Epoch 22/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0578 - val_accuracy: 0.5000\n",
            "Epoch 23/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 9.2550e-04 - accuracy: 1.0000 - val_loss: 3.0426 - val_accuracy: 0.5000\n",
            "Epoch 24/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 7.9469e-04 - accuracy: 1.0000 - val_loss: 3.0821 - val_accuracy: 0.5000\n",
            "Epoch 25/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 7.1099e-04 - accuracy: 1.0000 - val_loss: 3.0921 - val_accuracy: 0.5000\n",
            "Epoch 26/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 6.2693e-04 - accuracy: 1.0000 - val_loss: 3.1055 - val_accuracy: 0.5000\n",
            "Epoch 27/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 5.6219e-04 - accuracy: 1.0000 - val_loss: 3.1076 - val_accuracy: 0.5000\n",
            "Epoch 28/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 5.2064e-04 - accuracy: 1.0000 - val_loss: 3.1316 - val_accuracy: 0.5000\n",
            "Epoch 29/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 4.7288e-04 - accuracy: 1.0000 - val_loss: 3.1217 - val_accuracy: 0.5000\n",
            "Epoch 30/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 4.3816e-04 - accuracy: 1.0000 - val_loss: 3.1289 - val_accuracy: 0.5294\n",
            "Epoch 31/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 4.0478e-04 - accuracy: 1.0000 - val_loss: 3.1242 - val_accuracy: 0.5294\n",
            "Epoch 32/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.7256e-04 - accuracy: 1.0000 - val_loss: 3.1417 - val_accuracy: 0.5294\n",
            "Epoch 33/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.4812e-04 - accuracy: 1.0000 - val_loss: 3.1818 - val_accuracy: 0.5000\n",
            "Epoch 34/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.2727e-04 - accuracy: 1.0000 - val_loss: 3.1509 - val_accuracy: 0.5294\n",
            "Epoch 35/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.9873e-04 - accuracy: 1.0000 - val_loss: 3.1452 - val_accuracy: 0.5294\n",
            "Epoch 36/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.7390e-04 - accuracy: 1.0000 - val_loss: 3.1794 - val_accuracy: 0.5294\n",
            "Epoch 37/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.5573e-04 - accuracy: 1.0000 - val_loss: 3.1753 - val_accuracy: 0.5000\n",
            "Epoch 38/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 2.3561e-04 - accuracy: 1.0000 - val_loss: 3.1718 - val_accuracy: 0.5294\n",
            "Epoch 39/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.1738e-04 - accuracy: 1.0000 - val_loss: 3.1567 - val_accuracy: 0.5294\n",
            "Epoch 40/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.9992e-04 - accuracy: 1.0000 - val_loss: 3.1613 - val_accuracy: 0.5294\n",
            "Epoch 41/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.8699e-04 - accuracy: 1.0000 - val_loss: 3.1258 - val_accuracy: 0.5294\n",
            "Epoch 42/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.6842e-04 - accuracy: 1.0000 - val_loss: 3.1293 - val_accuracy: 0.5294\n",
            "Epoch 43/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.5251e-04 - accuracy: 1.0000 - val_loss: 3.1519 - val_accuracy: 0.5000\n",
            "Epoch 44/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.3588e-04 - accuracy: 1.0000 - val_loss: 3.1339 - val_accuracy: 0.5294\n",
            "Epoch 45/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.2268e-04 - accuracy: 1.0000 - val_loss: 3.1329 - val_accuracy: 0.5294\n",
            "Epoch 46/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.1084e-04 - accuracy: 1.0000 - val_loss: 3.1657 - val_accuracy: 0.5000\n",
            "Epoch 47/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.0041e-04 - accuracy: 1.0000 - val_loss: 3.1718 - val_accuracy: 0.5000\n",
            "Epoch 48/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 8.6925e-05 - accuracy: 1.0000 - val_loss: 3.1708 - val_accuracy: 0.5294\n",
            "Epoch 49/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 7.8396e-05 - accuracy: 1.0000 - val_loss: 3.1751 - val_accuracy: 0.5294\n",
            "Epoch 50/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 6.9323e-05 - accuracy: 1.0000 - val_loss: 3.1856 - val_accuracy: 0.5294\n",
            "Epoch 51/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 6.2342e-05 - accuracy: 1.0000 - val_loss: 3.1938 - val_accuracy: 0.5588\n",
            "Epoch 52/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 5.5832e-05 - accuracy: 1.0000 - val_loss: 3.2097 - val_accuracy: 0.5294\n",
            "Epoch 53/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 5.0851e-05 - accuracy: 1.0000 - val_loss: 3.1994 - val_accuracy: 0.5588\n",
            "Epoch 54/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 4.6647e-05 - accuracy: 1.0000 - val_loss: 3.2042 - val_accuracy: 0.5588\n",
            "Epoch 55/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 4.2502e-05 - accuracy: 1.0000 - val_loss: 3.2056 - val_accuracy: 0.5588\n",
            "Epoch 56/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.8456e-05 - accuracy: 1.0000 - val_loss: 3.2333 - val_accuracy: 0.5588\n",
            "Epoch 57/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 3.5692e-05 - accuracy: 1.0000 - val_loss: 3.2389 - val_accuracy: 0.5588\n",
            "Epoch 58/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 3.3316e-05 - accuracy: 1.0000 - val_loss: 3.2349 - val_accuracy: 0.5588\n",
            "Epoch 59/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.0920e-05 - accuracy: 1.0000 - val_loss: 3.2136 - val_accuracy: 0.5588\n",
            "Epoch 60/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 2.8516e-05 - accuracy: 1.0000 - val_loss: 3.2537 - val_accuracy: 0.5588\n",
            "Epoch 61/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 2.6086e-05 - accuracy: 1.0000 - val_loss: 3.2312 - val_accuracy: 0.5588\n",
            "Epoch 62/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.4356e-05 - accuracy: 1.0000 - val_loss: 3.2574 - val_accuracy: 0.5588\n",
            "Epoch 63/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.2881e-05 - accuracy: 1.0000 - val_loss: 3.2354 - val_accuracy: 0.5588\n",
            "Epoch 64/120\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 2.1423e-05 - accuracy: 1.0000 - val_loss: 3.2552 - val_accuracy: 0.5588\n",
            "Epoch 65/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.0116e-05 - accuracy: 1.0000 - val_loss: 3.2603 - val_accuracy: 0.5588\n",
            "Epoch 66/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.8993e-05 - accuracy: 1.0000 - val_loss: 3.2613 - val_accuracy: 0.5588\n",
            "Epoch 67/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.8040e-05 - accuracy: 1.0000 - val_loss: 3.2622 - val_accuracy: 0.5588\n",
            "Epoch 68/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.7127e-05 - accuracy: 1.0000 - val_loss: 3.2597 - val_accuracy: 0.5588\n",
            "Epoch 69/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.6135e-05 - accuracy: 1.0000 - val_loss: 3.2866 - val_accuracy: 0.5588\n",
            "Epoch 70/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.5444e-05 - accuracy: 1.0000 - val_loss: 3.2804 - val_accuracy: 0.5588\n",
            "Epoch 71/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.4665e-05 - accuracy: 1.0000 - val_loss: 3.2649 - val_accuracy: 0.5588\n",
            "Epoch 72/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.3961e-05 - accuracy: 1.0000 - val_loss: 3.2832 - val_accuracy: 0.5588\n",
            "Epoch 73/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.3314e-05 - accuracy: 1.0000 - val_loss: 3.2933 - val_accuracy: 0.5294\n",
            "Epoch 74/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.2744e-05 - accuracy: 1.0000 - val_loss: 3.2777 - val_accuracy: 0.5588\n",
            "Epoch 75/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.2186e-05 - accuracy: 1.0000 - val_loss: 3.3117 - val_accuracy: 0.5294\n",
            "Epoch 76/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.1603e-05 - accuracy: 1.0000 - val_loss: 3.2977 - val_accuracy: 0.5294\n",
            "Epoch 77/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 1.1075e-05 - accuracy: 1.0000 - val_loss: 3.3052 - val_accuracy: 0.5294\n",
            "Epoch 78/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.0669e-05 - accuracy: 1.0000 - val_loss: 3.3046 - val_accuracy: 0.5294\n",
            "Epoch 79/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 1.0111e-05 - accuracy: 1.0000 - val_loss: 3.3148 - val_accuracy: 0.5294\n",
            "Epoch 80/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 9.8007e-06 - accuracy: 1.0000 - val_loss: 3.2989 - val_accuracy: 0.5294\n",
            "Epoch 81/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 9.3075e-06 - accuracy: 1.0000 - val_loss: 3.3286 - val_accuracy: 0.5294\n",
            "Epoch 82/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 8.9352e-06 - accuracy: 1.0000 - val_loss: 3.3200 - val_accuracy: 0.5294\n",
            "Epoch 83/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 8.6225e-06 - accuracy: 1.0000 - val_loss: 3.3150 - val_accuracy: 0.5294\n",
            "Epoch 84/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 8.2243e-06 - accuracy: 1.0000 - val_loss: 3.3437 - val_accuracy: 0.5294\n",
            "Epoch 85/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 7.9436e-06 - accuracy: 1.0000 - val_loss: 3.3564 - val_accuracy: 0.5294\n",
            "Epoch 86/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 7.5748e-06 - accuracy: 1.0000 - val_loss: 3.3392 - val_accuracy: 0.5294\n",
            "Epoch 87/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 7.3225e-06 - accuracy: 1.0000 - val_loss: 3.3469 - val_accuracy: 0.5294\n",
            "Epoch 88/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 7.0021e-06 - accuracy: 1.0000 - val_loss: 3.3580 - val_accuracy: 0.5294\n",
            "Epoch 89/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 6.7403e-06 - accuracy: 1.0000 - val_loss: 3.3666 - val_accuracy: 0.5294\n",
            "Epoch 90/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 6.4130e-06 - accuracy: 1.0000 - val_loss: 3.3598 - val_accuracy: 0.5294\n",
            "Epoch 91/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 6.1702e-06 - accuracy: 1.0000 - val_loss: 3.3684 - val_accuracy: 0.5294\n",
            "Epoch 92/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 5.9716e-06 - accuracy: 1.0000 - val_loss: 3.3734 - val_accuracy: 0.5294\n",
            "Epoch 93/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 5.7038e-06 - accuracy: 1.0000 - val_loss: 3.4002 - val_accuracy: 0.5294\n",
            "Epoch 94/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 5.5112e-06 - accuracy: 1.0000 - val_loss: 3.3852 - val_accuracy: 0.5294\n",
            "Epoch 95/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 5.3013e-06 - accuracy: 1.0000 - val_loss: 3.4018 - val_accuracy: 0.5294\n",
            "Epoch 96/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 5.0793e-06 - accuracy: 1.0000 - val_loss: 3.4220 - val_accuracy: 0.5294\n",
            "Epoch 97/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 4.8771e-06 - accuracy: 1.0000 - val_loss: 3.4017 - val_accuracy: 0.5294\n",
            "Epoch 98/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 4.6914e-06 - accuracy: 1.0000 - val_loss: 3.4244 - val_accuracy: 0.5294\n",
            "Epoch 99/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 4.5385e-06 - accuracy: 1.0000 - val_loss: 3.4358 - val_accuracy: 0.5294\n",
            "Epoch 100/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 4.3718e-06 - accuracy: 1.0000 - val_loss: 3.4066 - val_accuracy: 0.5294\n",
            "Epoch 101/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 4.1844e-06 - accuracy: 1.0000 - val_loss: 3.4539 - val_accuracy: 0.5294\n",
            "Epoch 102/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 4.0194e-06 - accuracy: 1.0000 - val_loss: 3.4462 - val_accuracy: 0.5294\n",
            "Epoch 103/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 3.8786e-06 - accuracy: 1.0000 - val_loss: 3.4609 - val_accuracy: 0.5294\n",
            "Epoch 104/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.7499e-06 - accuracy: 1.0000 - val_loss: 3.4589 - val_accuracy: 0.5294\n",
            "Epoch 105/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.6393e-06 - accuracy: 1.0000 - val_loss: 3.4953 - val_accuracy: 0.5294\n",
            "Epoch 106/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.5097e-06 - accuracy: 1.0000 - val_loss: 3.4576 - val_accuracy: 0.5294\n",
            "Epoch 107/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.3439e-06 - accuracy: 1.0000 - val_loss: 3.4926 - val_accuracy: 0.5294\n",
            "Epoch 108/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 3.2290e-06 - accuracy: 1.0000 - val_loss: 3.5077 - val_accuracy: 0.5294\n",
            "Epoch 109/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.1080e-06 - accuracy: 1.0000 - val_loss: 3.5017 - val_accuracy: 0.5294\n",
            "Epoch 110/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 3.0053e-06 - accuracy: 1.0000 - val_loss: 3.5077 - val_accuracy: 0.5294\n",
            "Epoch 111/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 2.8981e-06 - accuracy: 1.0000 - val_loss: 3.5151 - val_accuracy: 0.5294\n",
            "Epoch 112/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.7858e-06 - accuracy: 1.0000 - val_loss: 3.5416 - val_accuracy: 0.5294\n",
            "Epoch 113/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.7167e-06 - accuracy: 1.0000 - val_loss: 3.5250 - val_accuracy: 0.5294\n",
            "Epoch 114/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.6010e-06 - accuracy: 1.0000 - val_loss: 3.5350 - val_accuracy: 0.5294\n",
            "Epoch 115/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 2.5276e-06 - accuracy: 1.0000 - val_loss: 3.5542 - val_accuracy: 0.5294\n",
            "Epoch 116/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.4403e-06 - accuracy: 1.0000 - val_loss: 3.5472 - val_accuracy: 0.5294\n",
            "Epoch 117/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.3522e-06 - accuracy: 1.0000 - val_loss: 3.5763 - val_accuracy: 0.5294\n",
            "Epoch 118/120\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 2.2883e-06 - accuracy: 1.0000 - val_loss: 3.5527 - val_accuracy: 0.5294\n",
            "Epoch 119/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.1984e-06 - accuracy: 1.0000 - val_loss: 3.5773 - val_accuracy: 0.5294\n",
            "Epoch 120/120\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 2.1233e-06 - accuracy: 1.0000 - val_loss: 3.5844 - val_accuracy: 0.5294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efffc05a190>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}