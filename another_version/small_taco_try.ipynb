{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small taco try",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "authorship_tag": "ABX9TyMikagezLb0Ed5YMwyQmSLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheClassicTechno/cleansea_model/blob/main/another_version/small_taco_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6i0R_D6Gk89",
        "outputId": "915cceb2-0ba0-4d7b-e3b6-40edc525ee82"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmfB3Q5xGXAy",
        "outputId": "c2d1c16e-261f-43ae-fc21-5cc5dba8a7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 172 files belonging to 5 classes.\n",
            "Using 138 files for training.\n",
            "Found 172 files belonging to 5 classes.\n",
            "Using 34 files for validation.\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_8 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 256, 256, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 128, 128, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 128, 128, 16)      0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 128, 128, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 64, 64, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 64, 64, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 32, 32, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 64)                1048640   \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,058,677\n",
            "Trainable params: 1,058,677\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "#processing images\n",
        "bottles1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/bottles'\n",
        "cans1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/cans'\n",
        "containers1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/containers'\n",
        "paper1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/paper'\n",
        "plastic1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/plastic'\n",
        "\n",
        "#all images are 227x227 in RGB so 227, 227, 3\n",
        "bottles = [cv2.imread(image) for image in glob.glob(bottles1)]\n",
        "cans = [cv2.imread(image) for image in glob.glob(cans1)]\n",
        "containers = [cv2.imread(image) for image in glob.glob(containers1)]\n",
        "paper = [cv2.imread(image) for image in glob.glob(paper1)]\n",
        "plastic = [cv2.imread(image) for image in glob.glob(plastic1)]\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/TEAM9SURESTART/taco',\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    seed = 24,  \n",
        "    image_size = (256, 256),\n",
        "    batch_size = 32\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/TEAM9SURESTART/taco',\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = 24,  \n",
        "    image_size = (256, 256),\n",
        "    batch_size = 32\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(train_dataset, val_dataset, test_size = 0.1, random_state = 1, stratify = val_dataset)\n",
        "\n",
        "from scipy.stats import zscore\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample df\n",
        "\n",
        "# Calculate the zscores and drop zscores into new column\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n",
        "model = Sequential ([\n",
        "    layers.Rescaling(1./255, input_shape = (256, 256, 3)),\n",
        "    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dense(5, activation = 'softmax')\n",
        "])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sE1BaEjvAfo_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])\n",
        "'''\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=['accuracy'],  run_eagerly=True\n",
        ")\n",
        "'''\n",
        "\n",
        "model.fit (\n",
        "    train_dataset, \n",
        "    validation_data = val_dataset,\n",
        "    epochs = 250\n",
        ")\n",
        "#model.save('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CaGQFS2Hlk6",
        "outputId": "b94402a7-b623-48c6-8d26-fde363f81b34"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 144ms/step - loss: 2.4048 - accuracy: 0.3188 - val_loss: 1.7082 - val_accuracy: 0.0588\n",
            "Epoch 2/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.7346 - accuracy: 0.2101 - val_loss: 1.6145 - val_accuracy: 0.1471\n",
            "Epoch 3/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.5869 - accuracy: 0.2029 - val_loss: 1.5978 - val_accuracy: 0.1471\n",
            "Epoch 4/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.5277 - accuracy: 0.2826 - val_loss: 1.5497 - val_accuracy: 0.3824\n",
            "Epoch 5/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.5022 - accuracy: 0.4203 - val_loss: 1.5521 - val_accuracy: 0.2353\n",
            "Epoch 6/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.5118 - accuracy: 0.3406 - val_loss: 1.5633 - val_accuracy: 0.2353\n",
            "Epoch 7/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.5079 - accuracy: 0.3116 - val_loss: 1.5558 - val_accuracy: 0.2647\n",
            "Epoch 8/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.4868 - accuracy: 0.3841 - val_loss: 1.5391 - val_accuracy: 0.1471\n",
            "Epoch 9/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.4467 - accuracy: 0.4058 - val_loss: 1.5205 - val_accuracy: 0.2647\n",
            "Epoch 10/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.4449 - accuracy: 0.3986 - val_loss: 1.5220 - val_accuracy: 0.2647\n",
            "Epoch 11/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.4328 - accuracy: 0.3696 - val_loss: 1.5124 - val_accuracy: 0.2941\n",
            "Epoch 12/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.3875 - accuracy: 0.4130 - val_loss: 1.5488 - val_accuracy: 0.1176\n",
            "Epoch 13/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.3473 - accuracy: 0.4855 - val_loss: 1.4540 - val_accuracy: 0.4118\n",
            "Epoch 14/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.2774 - accuracy: 0.5652 - val_loss: 1.4755 - val_accuracy: 0.3824\n",
            "Epoch 15/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.1611 - accuracy: 0.5725 - val_loss: 1.4615 - val_accuracy: 0.4118\n",
            "Epoch 16/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.1294 - accuracy: 0.6087 - val_loss: 1.4192 - val_accuracy: 0.4118\n",
            "Epoch 17/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.0915 - accuracy: 0.6014 - val_loss: 1.4379 - val_accuracy: 0.4118\n",
            "Epoch 18/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.9551 - accuracy: 0.7101 - val_loss: 1.4364 - val_accuracy: 0.3824\n",
            "Epoch 19/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.8627 - accuracy: 0.7174 - val_loss: 1.4558 - val_accuracy: 0.3824\n",
            "Epoch 20/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.7853 - accuracy: 0.7536 - val_loss: 1.5833 - val_accuracy: 0.4118\n",
            "Epoch 21/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.7772 - accuracy: 0.7391 - val_loss: 1.4776 - val_accuracy: 0.4706\n",
            "Epoch 22/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6576 - accuracy: 0.7826 - val_loss: 1.6146 - val_accuracy: 0.4118\n",
            "Epoch 23/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5671 - accuracy: 0.7899 - val_loss: 1.4604 - val_accuracy: 0.4412\n",
            "Epoch 24/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5322 - accuracy: 0.7971 - val_loss: 1.6735 - val_accuracy: 0.4118\n",
            "Epoch 25/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4516 - accuracy: 0.8478 - val_loss: 1.5277 - val_accuracy: 0.5000\n",
            "Epoch 26/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.3867 - accuracy: 0.8986 - val_loss: 1.7832 - val_accuracy: 0.4412\n",
            "Epoch 27/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3428 - accuracy: 0.9130 - val_loss: 1.7996 - val_accuracy: 0.5000\n",
            "Epoch 28/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.3577 - accuracy: 0.8623 - val_loss: 1.7306 - val_accuracy: 0.4706\n",
            "Epoch 29/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.2748 - accuracy: 0.9058 - val_loss: 1.7853 - val_accuracy: 0.4706\n",
            "Epoch 30/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2502 - accuracy: 0.9420 - val_loss: 1.7795 - val_accuracy: 0.5294\n",
            "Epoch 31/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2054 - accuracy: 0.9348 - val_loss: 1.8135 - val_accuracy: 0.5000\n",
            "Epoch 32/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1786 - accuracy: 0.9493 - val_loss: 2.1603 - val_accuracy: 0.4412\n",
            "Epoch 33/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1936 - accuracy: 0.9420 - val_loss: 2.0727 - val_accuracy: 0.5000\n",
            "Epoch 34/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1515 - accuracy: 0.9638 - val_loss: 2.3508 - val_accuracy: 0.5588\n",
            "Epoch 35/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.1220 - accuracy: 0.9855 - val_loss: 1.8875 - val_accuracy: 0.5294\n",
            "Epoch 36/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0965 - accuracy: 0.9855 - val_loss: 2.1021 - val_accuracy: 0.5000\n",
            "Epoch 37/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.4658 - accuracy: 0.8478 - val_loss: 1.8394 - val_accuracy: 0.5000\n",
            "Epoch 38/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3936 - accuracy: 0.8768 - val_loss: 1.6303 - val_accuracy: 0.4706\n",
            "Epoch 39/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3147 - accuracy: 0.9058 - val_loss: 1.9581 - val_accuracy: 0.5000\n",
            "Epoch 40/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2076 - accuracy: 0.9348 - val_loss: 1.9249 - val_accuracy: 0.5882\n",
            "Epoch 41/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2409 - accuracy: 0.9203 - val_loss: 1.6955 - val_accuracy: 0.5000\n",
            "Epoch 42/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.4426 - accuracy: 0.8333 - val_loss: 1.7832 - val_accuracy: 0.5000\n",
            "Epoch 43/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3253 - accuracy: 0.8841 - val_loss: 2.0103 - val_accuracy: 0.5294\n",
            "Epoch 44/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2063 - accuracy: 0.9565 - val_loss: 1.8740 - val_accuracy: 0.5000\n",
            "Epoch 45/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1743 - accuracy: 0.9420 - val_loss: 2.4817 - val_accuracy: 0.5588\n",
            "Epoch 46/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0648 - accuracy: 0.9928 - val_loss: 2.5922 - val_accuracy: 0.5588\n",
            "Epoch 47/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0320 - accuracy: 0.9928 - val_loss: 2.2335 - val_accuracy: 0.5294\n",
            "Epoch 48/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 2.1047 - val_accuracy: 0.5294\n",
            "Epoch 49/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.1457 - val_accuracy: 0.5294\n",
            "Epoch 50/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.2002 - val_accuracy: 0.5588\n",
            "Epoch 51/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.2558 - val_accuracy: 0.5000\n",
            "Epoch 52/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 2.2256 - val_accuracy: 0.5000\n",
            "Epoch 53/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.2336 - val_accuracy: 0.5000\n",
            "Epoch 54/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.1660 - val_accuracy: 0.4706\n",
            "Epoch 55/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.2512 - val_accuracy: 0.5294\n",
            "Epoch 56/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.3553 - val_accuracy: 0.5588\n",
            "Epoch 57/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.3985 - val_accuracy: 0.5588\n",
            "Epoch 58/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.4647 - val_accuracy: 0.5588\n",
            "Epoch 59/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.4474 - val_accuracy: 0.5588\n",
            "Epoch 60/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.3782 - val_accuracy: 0.5588\n",
            "Epoch 61/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.4091 - val_accuracy: 0.5294\n",
            "Epoch 62/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.4689 - val_accuracy: 0.5294\n",
            "Epoch 63/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.5233 - val_accuracy: 0.5588\n",
            "Epoch 64/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.5533 - val_accuracy: 0.5588\n",
            "Epoch 65/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.5734 - val_accuracy: 0.5882\n",
            "Epoch 66/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5452 - val_accuracy: 0.5882\n",
            "Epoch 67/250\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5004 - val_accuracy: 0.5294\n",
            "Epoch 68/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4622 - val_accuracy: 0.5588\n",
            "Epoch 69/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4716 - val_accuracy: 0.5588\n",
            "Epoch 70/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4934 - val_accuracy: 0.5588\n",
            "Epoch 71/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.5250 - val_accuracy: 0.5588\n",
            "Epoch 72/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.5367 - val_accuracy: 0.5588\n",
            "Epoch 73/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.5181 - val_accuracy: 0.5588\n",
            "Epoch 74/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.4661 - val_accuracy: 0.5588\n",
            "Epoch 75/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.5428 - val_accuracy: 0.5588\n",
            "Epoch 76/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.6297 - val_accuracy: 0.5588\n",
            "Epoch 77/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7537 - val_accuracy: 0.5294\n",
            "Epoch 78/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.8179 - val_accuracy: 0.5294\n",
            "Epoch 79/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.7449 - val_accuracy: 0.5294\n",
            "Epoch 80/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6609 - val_accuracy: 0.5294\n",
            "Epoch 81/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6166 - val_accuracy: 0.5294\n",
            "Epoch 82/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5935 - val_accuracy: 0.5588\n",
            "Epoch 83/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5578 - val_accuracy: 0.5882\n",
            "Epoch 84/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5668 - val_accuracy: 0.5882\n",
            "Epoch 85/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6014 - val_accuracy: 0.6471\n",
            "Epoch 86/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6212 - val_accuracy: 0.6471\n",
            "Epoch 87/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6429 - val_accuracy: 0.5588\n",
            "Epoch 88/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6878 - val_accuracy: 0.5588\n",
            "Epoch 89/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 9.1973e-04 - accuracy: 1.0000 - val_loss: 2.7407 - val_accuracy: 0.5588\n",
            "Epoch 90/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.7790 - val_accuracy: 0.5588\n",
            "Epoch 91/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8091 - val_accuracy: 0.5882\n",
            "Epoch 92/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8150 - val_accuracy: 0.5882\n",
            "Epoch 93/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7986 - val_accuracy: 0.5588\n",
            "Epoch 94/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7769 - val_accuracy: 0.5588\n",
            "Epoch 95/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7338 - val_accuracy: 0.5588\n",
            "Epoch 96/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 9.0176e-04 - accuracy: 1.0000 - val_loss: 2.7199 - val_accuracy: 0.5882\n",
            "Epoch 97/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7144 - val_accuracy: 0.5882\n",
            "Epoch 98/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7224 - val_accuracy: 0.5882\n",
            "Epoch 99/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 6.2105e-04 - accuracy: 1.0000 - val_loss: 2.7353 - val_accuracy: 0.5882\n",
            "Epoch 100/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 6.2260e-04 - accuracy: 1.0000 - val_loss: 2.7445 - val_accuracy: 0.5882\n",
            "Epoch 101/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 8.6651e-04 - accuracy: 1.0000 - val_loss: 2.7647 - val_accuracy: 0.5882\n",
            "Epoch 102/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 9.2217e-04 - accuracy: 1.0000 - val_loss: 2.7808 - val_accuracy: 0.5882\n",
            "Epoch 103/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8743 - val_accuracy: 0.5588\n",
            "Epoch 104/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 7.3963e-04 - accuracy: 1.0000 - val_loss: 2.9354 - val_accuracy: 0.5588\n",
            "Epoch 105/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9106 - val_accuracy: 0.5588\n",
            "Epoch 106/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8843 - val_accuracy: 0.5588\n",
            "Epoch 107/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 9.1734e-04 - accuracy: 1.0000 - val_loss: 2.8790 - val_accuracy: 0.5588\n",
            "Epoch 108/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.9050 - val_accuracy: 0.5588\n",
            "Epoch 109/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 8.0432e-04 - accuracy: 1.0000 - val_loss: 2.9222 - val_accuracy: 0.5588\n",
            "Epoch 110/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 9.2915e-04 - accuracy: 1.0000 - val_loss: 2.9467 - val_accuracy: 0.5882\n",
            "Epoch 111/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.9367 - val_accuracy: 0.5882\n",
            "Epoch 112/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 4.5484e-04 - accuracy: 1.0000 - val_loss: 2.9261 - val_accuracy: 0.5588\n",
            "Epoch 113/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 6.4516e-04 - accuracy: 1.0000 - val_loss: 2.9258 - val_accuracy: 0.5588\n",
            "Epoch 114/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 7.2951e-04 - accuracy: 1.0000 - val_loss: 2.9324 - val_accuracy: 0.5882\n",
            "Epoch 115/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9428 - val_accuracy: 0.5882\n",
            "Epoch 116/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9447 - val_accuracy: 0.5588\n",
            "Epoch 117/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 8.4453e-04 - accuracy: 1.0000 - val_loss: 2.9191 - val_accuracy: 0.5882\n",
            "Epoch 118/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 8.4185e-04 - accuracy: 1.0000 - val_loss: 2.9140 - val_accuracy: 0.5882\n",
            "Epoch 119/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9390 - val_accuracy: 0.5882\n",
            "Epoch 120/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 5.0810e-04 - accuracy: 1.0000 - val_loss: 2.9914 - val_accuracy: 0.5882\n",
            "Epoch 121/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0048 - val_accuracy: 0.5882\n",
            "Epoch 122/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 3.8171e-04 - accuracy: 1.0000 - val_loss: 3.0030 - val_accuracy: 0.5882\n",
            "Epoch 123/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 6.0486e-04 - accuracy: 1.0000 - val_loss: 3.0081 - val_accuracy: 0.5882\n",
            "Epoch 124/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 5.8180e-04 - accuracy: 1.0000 - val_loss: 3.0062 - val_accuracy: 0.5882\n",
            "Epoch 125/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 5.3127e-04 - accuracy: 1.0000 - val_loss: 2.9914 - val_accuracy: 0.5882\n",
            "Epoch 126/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 7.6822e-04 - accuracy: 1.0000 - val_loss: 2.9627 - val_accuracy: 0.5882\n",
            "Epoch 127/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.0280e-04 - accuracy: 1.0000 - val_loss: 2.9389 - val_accuracy: 0.5588\n",
            "Epoch 128/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 4.9766e-04 - accuracy: 1.0000 - val_loss: 2.9379 - val_accuracy: 0.5588\n",
            "Epoch 129/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.6753e-04 - accuracy: 1.0000 - val_loss: 2.9355 - val_accuracy: 0.5588\n",
            "Epoch 130/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 6.9860e-04 - accuracy: 1.0000 - val_loss: 2.9288 - val_accuracy: 0.5588\n",
            "Epoch 131/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 5.9019e-04 - accuracy: 1.0000 - val_loss: 2.9375 - val_accuracy: 0.5588\n",
            "Epoch 132/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 6.0057e-04 - accuracy: 1.0000 - val_loss: 2.9596 - val_accuracy: 0.5588\n",
            "Epoch 133/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.3510e-04 - accuracy: 1.0000 - val_loss: 2.9795 - val_accuracy: 0.5882\n",
            "Epoch 134/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 3.5099e-04 - accuracy: 1.0000 - val_loss: 2.9912 - val_accuracy: 0.5588\n",
            "Epoch 135/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 3.5940e-04 - accuracy: 1.0000 - val_loss: 2.9932 - val_accuracy: 0.5588\n",
            "Epoch 136/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 5.4628e-04 - accuracy: 1.0000 - val_loss: 2.9944 - val_accuracy: 0.5588\n",
            "Epoch 137/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 5.3937e-04 - accuracy: 1.0000 - val_loss: 2.9956 - val_accuracy: 0.5588\n",
            "Epoch 138/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 6.6872e-04 - accuracy: 1.0000 - val_loss: 2.9991 - val_accuracy: 0.5588\n",
            "Epoch 139/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 3.7145e-04 - accuracy: 1.0000 - val_loss: 3.0026 - val_accuracy: 0.5588\n",
            "Epoch 140/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 5.6967e-04 - accuracy: 1.0000 - val_loss: 2.9986 - val_accuracy: 0.5588\n",
            "Epoch 141/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0052 - val_accuracy: 0.5882\n",
            "Epoch 142/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 9.9415e-04 - accuracy: 1.0000 - val_loss: 3.0359 - val_accuracy: 0.5588\n",
            "Epoch 143/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 7.9103e-04 - accuracy: 1.0000 - val_loss: 3.0076 - val_accuracy: 0.5588\n",
            "Epoch 144/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.9518e-04 - accuracy: 1.0000 - val_loss: 2.9964 - val_accuracy: 0.5294\n",
            "Epoch 145/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 7.4973e-04 - accuracy: 1.0000 - val_loss: 2.9995 - val_accuracy: 0.5588\n",
            "Epoch 146/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.5652e-04 - accuracy: 1.0000 - val_loss: 3.0149 - val_accuracy: 0.5588\n",
            "Epoch 147/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 3.8202e-04 - accuracy: 1.0000 - val_loss: 3.0389 - val_accuracy: 0.5882\n",
            "Epoch 148/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 4.3264e-04 - accuracy: 1.0000 - val_loss: 3.0502 - val_accuracy: 0.5882\n",
            "Epoch 149/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.5172e-04 - accuracy: 1.0000 - val_loss: 3.0608 - val_accuracy: 0.5882\n",
            "Epoch 150/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.3037e-04 - accuracy: 1.0000 - val_loss: 3.0686 - val_accuracy: 0.5882\n",
            "Epoch 151/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.8833e-04 - accuracy: 1.0000 - val_loss: 3.0786 - val_accuracy: 0.5882\n",
            "Epoch 152/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 3.2925e-04 - accuracy: 1.0000 - val_loss: 3.0843 - val_accuracy: 0.5882\n",
            "Epoch 153/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 4.1908e-04 - accuracy: 1.0000 - val_loss: 3.0729 - val_accuracy: 0.5882\n",
            "Epoch 154/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.4363e-04 - accuracy: 1.0000 - val_loss: 3.0713 - val_accuracy: 0.5588\n",
            "Epoch 155/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.5713e-04 - accuracy: 1.0000 - val_loss: 3.0720 - val_accuracy: 0.5588\n",
            "Epoch 156/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.2652e-04 - accuracy: 1.0000 - val_loss: 3.0749 - val_accuracy: 0.5588\n",
            "Epoch 157/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 3.7408e-04 - accuracy: 1.0000 - val_loss: 3.0865 - val_accuracy: 0.5294\n",
            "Epoch 158/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.8665e-04 - accuracy: 1.0000 - val_loss: 3.0942 - val_accuracy: 0.5294\n",
            "Epoch 159/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 8.6485e-04 - accuracy: 1.0000 - val_loss: 3.0533 - val_accuracy: 0.5588\n",
            "Epoch 160/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 6.3271e-04 - accuracy: 1.0000 - val_loss: 3.0638 - val_accuracy: 0.5588\n",
            "Epoch 161/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.7699e-04 - accuracy: 1.0000 - val_loss: 3.0894 - val_accuracy: 0.5588\n",
            "Epoch 162/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 5.1873e-04 - accuracy: 1.0000 - val_loss: 3.1148 - val_accuracy: 0.5588\n",
            "Epoch 163/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.0737e-04 - accuracy: 1.0000 - val_loss: 3.1329 - val_accuracy: 0.5588\n",
            "Epoch 164/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.7420e-04 - accuracy: 1.0000 - val_loss: 3.1439 - val_accuracy: 0.5588\n",
            "Epoch 165/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.8449e-04 - accuracy: 1.0000 - val_loss: 3.1472 - val_accuracy: 0.5588\n",
            "Epoch 166/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.8373e-04 - accuracy: 1.0000 - val_loss: 3.1491 - val_accuracy: 0.5588\n",
            "Epoch 167/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.1134e-04 - accuracy: 1.0000 - val_loss: 3.1451 - val_accuracy: 0.5882\n",
            "Epoch 168/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 6.3274e-04 - accuracy: 1.0000 - val_loss: 3.1346 - val_accuracy: 0.5588\n",
            "Epoch 169/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.6205e-04 - accuracy: 1.0000 - val_loss: 3.1272 - val_accuracy: 0.5588\n",
            "Epoch 170/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.8812e-04 - accuracy: 1.0000 - val_loss: 3.1261 - val_accuracy: 0.5588\n",
            "Epoch 171/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1251 - val_accuracy: 0.5000\n",
            "Epoch 172/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.9102 - val_accuracy: 0.5294\n",
            "Epoch 173/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7102 - val_accuracy: 0.5294\n",
            "Epoch 174/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8931 - val_accuracy: 0.5294\n",
            "Epoch 175/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0582 - val_accuracy: 0.5588\n",
            "Epoch 176/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.1356 - val_accuracy: 0.6176\n",
            "Epoch 177/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1068 - val_accuracy: 0.6176\n",
            "Epoch 178/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 8.2019e-04 - accuracy: 1.0000 - val_loss: 3.0581 - val_accuracy: 0.6176\n",
            "Epoch 179/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0421 - val_accuracy: 0.5588\n",
            "Epoch 180/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 6.0983e-04 - accuracy: 1.0000 - val_loss: 3.2341 - val_accuracy: 0.5882\n",
            "Epoch 181/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.2815 - val_accuracy: 0.5882\n",
            "Epoch 182/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1852 - val_accuracy: 0.5294\n",
            "Epoch 183/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.8186e-04 - accuracy: 1.0000 - val_loss: 3.1497 - val_accuracy: 0.5294\n",
            "Epoch 184/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.6794e-04 - accuracy: 1.0000 - val_loss: 3.1457 - val_accuracy: 0.5294\n",
            "Epoch 185/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 5.9126e-04 - accuracy: 1.0000 - val_loss: 3.1427 - val_accuracy: 0.5294\n",
            "Epoch 186/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.9075e-04 - accuracy: 1.0000 - val_loss: 3.1409 - val_accuracy: 0.5294\n",
            "Epoch 187/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.1835e-04 - accuracy: 1.0000 - val_loss: 3.1291 - val_accuracy: 0.5588\n",
            "Epoch 188/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 6.9231e-04 - accuracy: 1.0000 - val_loss: 3.1440 - val_accuracy: 0.5588\n",
            "Epoch 189/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.6930e-04 - accuracy: 1.0000 - val_loss: 3.1529 - val_accuracy: 0.5588\n",
            "Epoch 190/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.1944e-04 - accuracy: 1.0000 - val_loss: 3.1647 - val_accuracy: 0.5588\n",
            "Epoch 191/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 2.3116e-04 - accuracy: 1.0000 - val_loss: 3.1690 - val_accuracy: 0.5588\n",
            "Epoch 192/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.7744e-04 - accuracy: 1.0000 - val_loss: 3.1729 - val_accuracy: 0.5588\n",
            "Epoch 193/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.8702e-04 - accuracy: 1.0000 - val_loss: 3.1934 - val_accuracy: 0.5588\n",
            "Epoch 194/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.2813e-04 - accuracy: 1.0000 - val_loss: 3.2100 - val_accuracy: 0.5882\n",
            "Epoch 195/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 2.3213e-04 - accuracy: 1.0000 - val_loss: 3.2183 - val_accuracy: 0.5882\n",
            "Epoch 196/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.1491e-04 - accuracy: 1.0000 - val_loss: 3.2207 - val_accuracy: 0.5882\n",
            "Epoch 197/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.6654e-04 - accuracy: 1.0000 - val_loss: 3.2245 - val_accuracy: 0.5882\n",
            "Epoch 198/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.0378e-04 - accuracy: 1.0000 - val_loss: 3.2297 - val_accuracy: 0.5882\n",
            "Epoch 199/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.2585e-04 - accuracy: 1.0000 - val_loss: 3.2376 - val_accuracy: 0.5882\n",
            "Epoch 200/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 3.1626e-04 - accuracy: 1.0000 - val_loss: 3.2435 - val_accuracy: 0.5882\n",
            "Epoch 201/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.1614e-04 - accuracy: 1.0000 - val_loss: 3.2253 - val_accuracy: 0.5882\n",
            "Epoch 202/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.9219e-04 - accuracy: 1.0000 - val_loss: 3.2102 - val_accuracy: 0.5882\n",
            "Epoch 203/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 2.6110e-04 - accuracy: 1.0000 - val_loss: 3.2111 - val_accuracy: 0.5882\n",
            "Epoch 204/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.1963e-04 - accuracy: 1.0000 - val_loss: 3.2264 - val_accuracy: 0.5882\n",
            "Epoch 205/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.5554e-04 - accuracy: 1.0000 - val_loss: 3.2290 - val_accuracy: 0.5882\n",
            "Epoch 206/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 9.5180e-05 - accuracy: 1.0000 - val_loss: 3.2285 - val_accuracy: 0.5882\n",
            "Epoch 207/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.8289e-04 - accuracy: 1.0000 - val_loss: 3.2344 - val_accuracy: 0.5882\n",
            "Epoch 208/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 2.7676e-04 - accuracy: 1.0000 - val_loss: 3.2411 - val_accuracy: 0.5882\n",
            "Epoch 209/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.1440e-04 - accuracy: 1.0000 - val_loss: 3.2469 - val_accuracy: 0.5882\n",
            "Epoch 210/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 3.0154e-04 - accuracy: 1.0000 - val_loss: 3.2657 - val_accuracy: 0.5882\n",
            "Epoch 211/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.5344e-04 - accuracy: 1.0000 - val_loss: 3.2843 - val_accuracy: 0.5882\n",
            "Epoch 212/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.0635e-04 - accuracy: 1.0000 - val_loss: 3.2964 - val_accuracy: 0.5882\n",
            "Epoch 213/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.1855e-04 - accuracy: 1.0000 - val_loss: 3.2828 - val_accuracy: 0.5882\n",
            "Epoch 214/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.9855e-04 - accuracy: 1.0000 - val_loss: 3.2548 - val_accuracy: 0.5882\n",
            "Epoch 215/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.1077e-04 - accuracy: 1.0000 - val_loss: 3.2297 - val_accuracy: 0.5882\n",
            "Epoch 216/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.6932e-04 - accuracy: 1.0000 - val_loss: 3.2167 - val_accuracy: 0.5588\n",
            "Epoch 217/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.5171e-04 - accuracy: 1.0000 - val_loss: 3.2155 - val_accuracy: 0.5588\n",
            "Epoch 218/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.8932e-04 - accuracy: 1.0000 - val_loss: 3.2232 - val_accuracy: 0.5588\n",
            "Epoch 219/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.5446e-04 - accuracy: 1.0000 - val_loss: 3.2474 - val_accuracy: 0.5588\n",
            "Epoch 220/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 9.2228e-05 - accuracy: 1.0000 - val_loss: 3.2640 - val_accuracy: 0.5588\n",
            "Epoch 221/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.2151e-04 - accuracy: 1.0000 - val_loss: 3.2716 - val_accuracy: 0.5588\n",
            "Epoch 222/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.2961e-04 - accuracy: 1.0000 - val_loss: 3.2738 - val_accuracy: 0.5588\n",
            "Epoch 223/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.2187e-04 - accuracy: 1.0000 - val_loss: 3.2686 - val_accuracy: 0.5588\n",
            "Epoch 224/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.3192e-04 - accuracy: 1.0000 - val_loss: 3.2627 - val_accuracy: 0.5588\n",
            "Epoch 225/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 6.0196e-05 - accuracy: 1.0000 - val_loss: 3.2573 - val_accuracy: 0.5588\n",
            "Epoch 226/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.0768e-04 - accuracy: 1.0000 - val_loss: 3.2595 - val_accuracy: 0.5588\n",
            "Epoch 227/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.1296e-04 - accuracy: 1.0000 - val_loss: 3.2626 - val_accuracy: 0.5882\n",
            "Epoch 228/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.1384e-04 - accuracy: 1.0000 - val_loss: 3.2633 - val_accuracy: 0.5882\n",
            "Epoch 229/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.5024e-04 - accuracy: 1.0000 - val_loss: 3.2639 - val_accuracy: 0.5882\n",
            "Epoch 230/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.1862e-04 - accuracy: 1.0000 - val_loss: 3.2650 - val_accuracy: 0.5882\n",
            "Epoch 231/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 8.1336e-05 - accuracy: 1.0000 - val_loss: 3.2673 - val_accuracy: 0.5882\n",
            "Epoch 232/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 5.8107e-04 - accuracy: 1.0000 - val_loss: 3.3593 - val_accuracy: 0.5588\n",
            "Epoch 233/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 6.1088e-04 - accuracy: 1.0000 - val_loss: 3.3760 - val_accuracy: 0.5588\n",
            "Epoch 234/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 8.9558e-05 - accuracy: 1.0000 - val_loss: 3.2792 - val_accuracy: 0.5588\n",
            "Epoch 235/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.9243e-04 - accuracy: 1.0000 - val_loss: 3.2411 - val_accuracy: 0.5294\n",
            "Epoch 236/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.3250e-04 - accuracy: 1.0000 - val_loss: 3.2251 - val_accuracy: 0.5294\n",
            "Epoch 237/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.4436e-04 - accuracy: 1.0000 - val_loss: 3.2265 - val_accuracy: 0.5294\n",
            "Epoch 238/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.7400e-04 - accuracy: 1.0000 - val_loss: 3.2297 - val_accuracy: 0.5588\n",
            "Epoch 239/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.3115e-04 - accuracy: 1.0000 - val_loss: 3.2412 - val_accuracy: 0.5588\n",
            "Epoch 240/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.4093e-04 - accuracy: 1.0000 - val_loss: 3.2452 - val_accuracy: 0.5588\n",
            "Epoch 241/250\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.4598e-04 - accuracy: 1.0000 - val_loss: 3.2501 - val_accuracy: 0.5588\n",
            "Epoch 242/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.2475e-04 - accuracy: 1.0000 - val_loss: 3.2430 - val_accuracy: 0.5588\n",
            "Epoch 243/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.1076e-04 - accuracy: 1.0000 - val_loss: 3.2458 - val_accuracy: 0.5588\n",
            "Epoch 244/250\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 8.3618e-05 - accuracy: 1.0000 - val_loss: 3.2548 - val_accuracy: 0.5588\n",
            "Epoch 245/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 5.3668e-04 - accuracy: 1.0000 - val_loss: 3.3182 - val_accuracy: 0.5588\n",
            "Epoch 246/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.5432e-04 - accuracy: 1.0000 - val_loss: 3.4562 - val_accuracy: 0.5588\n",
            "Epoch 247/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.4296e-04 - accuracy: 1.0000 - val_loss: 3.5360 - val_accuracy: 0.5588\n",
            "Epoch 248/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.2074 - val_accuracy: 0.5588\n",
            "Epoch 249/250\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.2145 - val_accuracy: 0.5588\n",
            "Epoch 250/250\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 3.2884 - val_accuracy: 0.5294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efede163890>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = pd.DataFrame(model.history.history)\n",
        "\n",
        "#plotting the loss and accuracy \n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(loss[\"loss\"], label =\"Loss\")\n",
        "plt.plot(loss[\"val_loss\"], label = \"Validation_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss['accuracy'],label = \"Training Accuracy\")\n",
        "plt.plot(loss['val_accuracy'], label =\"Validation_ Accuracy \")\n",
        "plt.legend()\n",
        "plt.title(\"Training-Validation Accuracy\")"
      ],
      "metadata": {
        "id": "JvWzB_usAAvy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}